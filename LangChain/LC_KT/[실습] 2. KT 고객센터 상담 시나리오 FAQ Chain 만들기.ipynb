{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%pip install -U langchain langchain-core langchain-community langchain-openai azure-search-documents azure-identity",
   "id": "15305232748419a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# í™˜ê²½ ì„¤ì • Import\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "ff14a557be8b3984"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# KT ê³ ê°ì„¼í„° ìƒë‹´ ì‹œë‚˜ë¦¬ì˜¤ FAQ - LCEL Chain ìœ¼ë¡œ ë§Œë“¤ê¸°",
   "id": "d0af433087333a79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ë°ì´í„° ì¶œì²˜: https://ermsweb.kt.com/pc/faq/faqList.do\n",
    "import json\n",
    "category = [\n",
    "    \"USIM\",\n",
    "    \"ëª¨ë°”ì¼\",\n",
    "    \"í˜œíƒ\",\n",
    "    \"ê²°í•©\",\n",
    "    \"ì¸í„°ë„·\",\n",
    "    \"tv\",\n",
    "    \"ì§‘ì „í™”\",\n",
    "    \"ì¸í„°ë„·ì „í™”\",\n",
    "    \"IoT\",\n",
    "    \"Egg\",\n",
    "    \"ì™€ì´íŒŒì´\",\n",
    "    \"ê¸°íƒ€\",\n",
    "    \"SHOP\",\n",
    "]\n",
    "\n",
    "def load_faq_data(file_path=\"faq_data.json\"):\n",
    "    \"\"\"FAQ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            result = json.load(f)\n",
    "    except json.decoder.JSONDecodeError as e:\n",
    "        print(f\"[ERROR] JSONDecode: {e}\")\n",
    "    return result\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "faq_data = load_faq_data()"
   ],
   "id": "6488e9c76e37b542",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. FAQ ë°ì´í„° ì „ì²˜ë¦¬",
   "id": "ae3df1b509dc5bce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1) Load and Parse ë¥¼ í•  í•„ìš”ê°€ ì—†ìŒ -> ì´ë¯¸ ë‹¤ íŒŒì‹±ë˜ì–´ JSON ìœ¼ë¡œ ìˆìŠµë‹ˆë‹¤\"\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(category)\n",
    "print(\"==\" * 100)\n",
    "pprint(faq_data)"
   ],
   "id": "8868f8ffc65480c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.1 LangChain Document ê°ì²´ ì´í•´",
   "id": "deefebab933cbc29"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "sample_doc = Document(\n",
    "    page_content=\"ì´ê²ƒì€ ë¬¸ì„œì˜ ë‚´ìš©ì…ë‹ˆë‹¤.\\nì‹¤ì œ í…ìŠ¤íŠ¸ê°€ ì—¬ê¸°ì— ë“¤ì–´ê°€ê²Œ ë˜ê³ , ì´ ë‚´ìš© ì „ì²´ê°€ Embedding ëŒ€ìƒì¸ Chunk ì…ë‹ˆë‹¤.\",\n",
    "    metadata={\n",
    "        \"source\": \"faq\",\n",
    "        \"category\": \"ì˜ˆì œ\",\n",
    "        \"id\": 1\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"<<LangChain Document êµ¬ì¡°>>\")\n",
    "print(f\"- page_content: {sample_doc.page_content}\")\n",
    "print(f\"- metadata: {sample_doc.metadata} \\n  ë©”íƒ€ë°ì´í„°ëŠ” Filtering ì— ì‚¬ìš©ë©ë‹ˆë‹¤. (RDB ì˜ Where ì¡°ê±´ì ˆ)\")"
   ],
   "id": "68a6c3dcc6dbe34d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. FAQ ë°ì´í„° Embedding",
   "id": "7a8c03558f807502"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from uuid import uuid4\n",
    "from langchain_openai import AzureOpenAIEmbeddings, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=\"text-embedding-3-small\",\n",
    "    openai_api_version=\"2024-02-01\",\n",
    ")\n",
    "\n",
    "#Azure AI Search(VectorDB)\n",
    "vector_store = AzureSearch(\n",
    "    azure_search_endpoint=f\"https://{os.environ['AZURE_AI_SEARCH_SERVICE_NAME']}.search.windows.net\",\n",
    "    azure_search_key=os.environ[\"AZURE_AI_SEARCH_API_KEY\"],\n",
    "    index_name=\"faq-index\",\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "print(embeddings)\n",
    "print(vector_store)"
   ],
   "id": "e0b313ca79138157",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# JSON to Langchain Document\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def json_to_document(json_data: dict):\n",
    "    documents = []\n",
    "    for cat, qa_list in json_data.items():\n",
    "        print(f\"Category: {cat}\")\n",
    "        for _, qa_item in enumerate(qa_list):\n",
    "                doc = Document(\n",
    "                    page_content=f\"Category: {cat}\\nQuestion: {qa_item['question']}\\nAnswer: {qa_item['answer']}\",\n",
    "                    metadata={\n",
    "                        \"category\": cat,\n",
    "                        \"source\": \"faq\"\n",
    "                    }\n",
    "                )\n",
    "                documents.append(doc)\n",
    "    return documents\n",
    "\n",
    "docs = json_to_document(faq_data)\n",
    "uuids = [str(uuid4()) for _ in range(len(docs))]\n",
    "\n",
    "# Vector DB ì— ì €ì¥\n",
    "vector_store.add_documents(documents=docs, ids=uuids)"
   ],
   "id": "2210d7591ea23812",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ë‹¨ìˆœ ìœ ì‚¬ë„ ê²€ìƒ‰\n",
    "from langchain_core.vectorstores import VectorStore\n",
    "\n",
    "def search_simple_cos(input_vector_store: VectorStore, query: str, k: int = 3):\n",
    "    _results = input_vector_store.similarity_search(query, k=k)\n",
    "    return _results\n",
    "\n",
    "test_question = \"usim\"\n",
    "results = search_simple_cos(vector_store, test_question, k=1)\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ],
   "id": "441304e8b40177ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ë‹¨ìˆœ Cosine Similarity with Score (ìŠ¤ì½”ì–´ê¹Œì§€ ë³´ì—¬ì¤Œ)\n",
    "\n",
    "def search_simple_cos_with_score(input_vector_store: VectorStore, query: str, k: int = 3):\n",
    "    _results = input_vector_store.similarity_search_with_score(query, k=k)\n",
    "    return _results\n",
    "\n",
    "score_question = \"ì¸í„°ë„·\"\n",
    "results = search_simple_cos_with_score(vector_store, score_question, k=1)\n",
    "for res, score in results:\n",
    "    print(f\"* [SCORE={score:3f}]\\n{res.page_content} [{res.metadata}]\")"
   ],
   "id": "f77bb39c878ade86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Retriever Customizing ì‹¤ë¬´ìš©\n",
    "def custom_retriever(k: int = 3, fetch_k: int = 5, filter: dict | None = None):\n",
    "    result = vector_store.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\"k\": k, \"fetch_k\": fetch_k,\n",
    "                       \"filter\": filter}\n",
    "    )\n",
    "    return result\n",
    "\n",
    "_custom_r = custom_retriever()\n",
    "\n",
    "real_question = \"USIMê°€ì… ì ˆì°¨ëŠ”?\"\n",
    "real_filter = {\n",
    "    \"category\": \"USIMê°€ì…\"\n",
    "}\n",
    "_custom_r.invoke(real_question, filter=real_filter)"
   ],
   "id": "f68252eccf4727a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1 Hybrid Search (Semantic + **Lexical**)",
   "id": "2874a2181982463"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Lexical Search Retriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "# ì„¤ì¹˜ í•„ìš”\n",
    "# %pip install rank_bm25\n",
    "\n",
    "bm25_rr = BM25Retriever.from_documents(docs)\n",
    "bm25_rr.invoke(\"ì¸í„°ë„· ìš”ê¸ˆì´ ì™œ ì´ë ‡ê²Œ ë§ì´ ë‚˜ì™”ë‚˜ìš”?\", k=3)"
   ],
   "id": "fe5b3bd10690b09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# í˜•íƒœì†Œ ë¶„ì„ê¸° ì„¤ì¹˜\n",
    "# %pip install kiwipiepy konlpy"
   ],
   "id": "cc48b6b5ab49fff5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ê·¸ë˜ì„œ ì–´ë–¤ Lexical(TF-IDF ê¸°ë°˜) Search Retriever ë¥¼ ì“°ë©´ ë˜ëŠ”ì§€?\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "ensemble_rr = EnsembleRetriever(\n",
    "    retrievers=[\n",
    "        bm25_rr,  # Lexical Retriever\n",
    "        vector_store.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 3})  # Vector Retriever\n",
    "    ],\n",
    "    weights=[0.5, 0.5]  # ê° ê²€ìƒ‰ê¸°ì˜ ê°€ì¤‘ì¹˜\n",
    ")"
   ],
   "id": "2db78779e6da107c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ensemble_rr.invoke(\"ì¸í„°ë„· ìš”ê¸ˆì´ ì™œ ì´ë ‡ê²Œ ë§ì´ ë‚˜ì™”ë‚˜ìš”?\")",
   "id": "78241976485f6897",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ì¶”ì²œí•˜ëŠ” ë°©ì‹ì€ í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸°ê°€ ë‹¬ë¦° BM25(TF-IDF ê¸°ë°˜) ê²€ìƒ‰ê¸°ë¥¼ ì‚¬ìš©ì„ ê¸°ë³¸ìœ¼ë¡œ í•˜ëŠ” Custom Retriever ë¥¼ ë§Œë“œëŠ” ê²ƒ\n",
    "# NOTE: ë°”ë¡œ ê°€ì ¸ë‹¤ ì“°ì…”ë„ ë©ë‹ˆë‹¤^^\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, Callable, Dict, Iterable, List, Optional\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "\n",
    "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "from langchain_core.documents import Document\n",
    "from pydantic import Field\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "\n",
    "try:\n",
    "    from kiwipiepy import Kiwi\n",
    "except ImportError:\n",
    "    raise ImportError(\n",
    "        \"Could not import kiwipiepy, please install with `pip install kiwipiepy`.\"\n",
    "    )\n",
    "\n",
    "kiwi_tokenizer = Kiwi()\n",
    "\n",
    "\n",
    "def kiwi_preprocessing_func(text: str) -> List[str]:\n",
    "    return [token.form for token in kiwi_tokenizer.tokenize(text)]\n",
    "\n",
    "\n",
    "def default_preprocessing_func(text: str) -> List[str]:\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "class KiwiBM25Retriever(BaseRetriever):\n",
    "    \"\"\"`BM25` retriever without Elasticsearch and Add Kiwi Tokenizer\"\"\"\n",
    "\n",
    "    vectorizer: Any\n",
    "    \"\"\" BM25 vectorizer.\"\"\"\n",
    "    docs: List[Document] = Field(repr=False)\n",
    "    \"\"\" List of documents.\"\"\"\n",
    "    k: int = 5\n",
    "    \"\"\" Number of documents to return.\"\"\"\n",
    "    preprocess_func: Callable[[str], List[str]] = kiwi_preprocessing_func\n",
    "    \"\"\" Preprocessing function to use on the text before BM25 vectorization.\"\"\"\n",
    "\n",
    "    class Config:\n",
    "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
    "\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    @classmethod\n",
    "    def from_texts(\n",
    "        cls,\n",
    "        texts: Iterable[str],\n",
    "        meta_data: Optional[Iterable[dict]] = None,\n",
    "        bm25_params: Optional[Dict[str, Any]] = None,\n",
    "        preprocess_func: Callable[[str], List[str]] = kiwi_preprocessing_func,\n",
    "        **kwargs: Any,\n",
    "    ) -> KiwiBM25Retriever:\n",
    "        \"\"\"\n",
    "        Create a KiwiBM25Retriever from a list of texts.\n",
    "        Args:\n",
    "            texts: A list of texts to vectorize.\n",
    "            meta_data: A list of metadata dicts to associate with each text.\n",
    "            bm25_params: Parameters to pass to the BM25 vectorizer.\n",
    "            preprocess_func: A function to preprocess each text before vectorization.\n",
    "            **kwargs: Any other arguments to pass to the retriever.\n",
    "\n",
    "        Returns:\n",
    "            A KiwiBM25Retriever instance.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            from rank_bm25 import BM25Okapi\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"Could not import rank_bm25, please install with `pip install \"\n",
    "                \"rank_bm25`.\"\n",
    "            )\n",
    "\n",
    "        texts_processed = [preprocess_func(t) for t in texts]\n",
    "        bm25_params = bm25_params or {}\n",
    "        vectorizer = BM25Okapi(texts_processed, **bm25_params)\n",
    "        meta_data = meta_data or ({} for _ in texts)\n",
    "        docs = [Document(page_content=t, metadata=m) for t, m in zip(texts, meta_data)]\n",
    "        return cls(\n",
    "            vectorizer=vectorizer, docs=docs, preprocess_func=preprocess_func, **kwargs\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_documents(\n",
    "        cls,\n",
    "        documents: Iterable[Document],\n",
    "        *,\n",
    "        bm25_params: Optional[Dict[str, Any]] = None,\n",
    "        preprocess_func: Callable[[str], List[str]] = kiwi_preprocessing_func,\n",
    "        **kwargs: Any,\n",
    "    ) -> KiwiBM25Retriever:\n",
    "        \"\"\"\n",
    "        Create a KiwiBM25Retriever from a list of Documents.\n",
    "        Args:\n",
    "            documents: A list of Documents to vectorize.\n",
    "            bm25_params: Parameters to pass to the BM25 vectorizer.\n",
    "            preprocess_func: A function to preprocess each text before vectorization.\n",
    "            **kwargs: Any other arguments to pass to the retriever.\n",
    "\n",
    "        Returns:\n",
    "            A KiwiBM25Retriever instance.\n",
    "        \"\"\"\n",
    "        texts, meta_data = zip(*((d.page_content, d.metadata) for d in documents))\n",
    "        return cls.from_texts(\n",
    "            texts=texts,\n",
    "            bm25_params=bm25_params,\n",
    "            metadatas=meta_data,\n",
    "            preprocess_func=preprocess_func,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        processed_query = self.preprocess_func(query)\n",
    "        return_docs = self.vectorizer.get_top_n(processed_query, self.docs, n=self.k)\n",
    "        return return_docs\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum(axis=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def argsort(seq, reverse):\n",
    "        return sorted(range(len(seq)), key=seq.__getitem__, reverse=reverse)\n",
    "\n",
    "    def search_with_score(self, query: str, top_k=None):\n",
    "        normalized_score = KiwiBM25Retriever.softmax(\n",
    "            self.vectorizer.get_scores(self.preprocess_func(query))\n",
    "        )\n",
    "\n",
    "        if top_k is None:\n",
    "            top_k = self.k\n",
    "\n",
    "        score_indexes = KiwiBM25Retriever.argsort(normalized_score, True)\n",
    "\n",
    "        docs_with_scores = []\n",
    "        for i, doc in enumerate(self.docs):\n",
    "            document = Document(\n",
    "                page_content=doc.page_content, metadata={\"score\": normalized_score[i]}\n",
    "            )\n",
    "            docs_with_scores.append(document)\n",
    "\n",
    "        score_indexes = score_indexes[:top_k]\n",
    "\n",
    "        # Creating an itemgetter object\n",
    "        getter = itemgetter(*score_indexes)\n",
    "\n",
    "        # Using itemgetter to get items\n",
    "        selected_elements = getter(docs_with_scores)\n",
    "        return selected_elements"
   ],
   "id": "f36409d3ccf99173",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ê·¸ëŸ¼ ìµœì¢…ì ìœ¼ë¡œ Hybrid Search Retriever ë¥¼ EnsembleRetriever ë¡œ ë§Œë“¤ì–´ë³¸ë‹¤ë©´?\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[\n",
    "        KiwiBM25Retriever.from_documents(docs),  # Kiwi BM25 Retriever\n",
    "        vector_store.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 3})  # Vector Retriever\n",
    "    ],\n",
    "    weights=[0.7, 0.3]  # ê° ê²€ìƒ‰ê¸°ì˜ ê°€ì¤‘ì¹˜\n",
    ")\n",
    "\n",
    "\n",
    "hybrid_retriever.invoke(\"ì¸í„°ë„· ìš”ê¸ˆì´ ì™œ ì´ë ‡ê²Œ ë§ì´ ë‚˜ì™”ë‚˜ìš”?\")"
   ],
   "id": "93c5717425f75c59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2 í…ìŠ¤íŠ¸ ë¶„í• (Text Splitting)",
   "id": "a4358ebf073ecf1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ë¶„í• ê¸° ìƒì„±\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,      # ì²­í¬ í¬ê¸°(500 ì´í•˜ë¡œ ì¶”ì²œ)\n",
    "    chunk_overlap=50,    # ì²­í¬ ê°„ ê²¹ì¹¨\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]  # ë¶„í•  ìš°ì„  ìˆœìœ„\n",
    ")\n",
    "\n",
    "# ë¬¸ì„œ ë¶„í• \n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "print(f\"âœ… {len(docs)}ê°œ ë¬¸ì„œ â†’ {len(split_docs)}ê°œ ì²­í¬ë¡œ ë¶„í• \")\n",
    "\n",
    "# ë¶„í•  ê²°ê³¼ í™•ì¸\n",
    "print(\"\\nğŸ” ë¶„í•  ì˜ˆì‹œ:\")\n",
    "print(f\"ì›ë³¸ ë¬¸ì„œ ê¸¸ì´: {len(docs[0].page_content)}ì\")\n",
    "if len(split_docs) > len(docs):\n",
    "    print(f\"ë¶„í• ëœ ì²« ë²ˆì§¸ ì²­í¬: {split_docs[0].page_content}\")"
   ],
   "id": "4bdaa7a5511195cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. FAQ LCEL Chain ë§Œë“¤ê¸°",
   "id": "52564d00f0a500d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def format_docs(docs: list[Document]) -> str:\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…\n",
    "\n",
    "    Args:\n",
    "        docs: Document ê°ì²´ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    formatted = []\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        formatted.append(f\"[Document Context_{i}]\\n{doc.page_content}]\")\n",
    "\n",
    "    return \"\\n\\n\".join(formatted)"
   ],
   "id": "e03e414f007b0780",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sys_prompt = \"\"\"ë‹¹ì‹ ì€ KT ê³ ê°ì„¼í„° ìƒë‹´ì›ì…ë‹ˆë‹¤.\n",
    "ë¬´ì¡°ê±´ ì•„ë˜ ì°¸ê³  ìë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ ê³ ê°ì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ì œê³µëœ ìë£Œë§Œì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "-----\n",
    "ì°¸ê³  ìë£Œ:\n",
    "{context}\n",
    "-----\n",
    "\"\"\""
   ],
   "id": "9bb5b7b39dab495c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(sys_prompt),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\"),\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "prompt"
   ],
   "id": "f036cb30bb8f3b52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings, ChatOpenAI\n",
    "\n",
    "###\n",
    "deployment = \"gpt-4.1-nano\" # ëª¨ë¸ Deployment ì´ë¦„\n",
    "api_version=\"2025-01-01-preview\"\n",
    "###\n",
    "\n",
    "rag_model = AzureChatOpenAI(\n",
    "    azure_deployment=deployment,\n",
    "    api_version=api_version,\n",
    "    temperature=0.1,\n",
    ")"
   ],
   "id": "86c9894bf4d9d877",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Chain ìƒì„±\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "naive_chain = {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} | prompt | rag_model\n",
    "\n",
    "naive_chain"
   ],
   "id": "bb65491ee3b18228",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. FAQ Chain ì‹¤í–‰",
   "id": "15570b2cdcf0db66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "user_question = \"ì¸í„°ë„·ì´ ìê¾¸ ëŠê²¨ìš”. ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?\"\n",
    "response = naive_chain.invoke(user_question)\n",
    "\n",
    "response.pretty_print()"
   ],
   "id": "4607d2320752c008",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. FAQ Chain ì—…ê·¸ë ˆì´ë“œ",
   "id": "b15b27ee93e39200"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.1 Few-shot Prompt",
   "id": "9ae758b848578545"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"íœ´ëŒ€í° ìš”ê¸ˆì´ ë„ˆë¬´ ë¹„ì‹¸ìš”\",\n",
    "        \"output\": \"\"\"ê³ ê°ë‹˜, íœ´ëŒ€í° ìš”ê¸ˆ ë¶€ë‹´ì„ ëœì–´ë“œë¦´ ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "1. **ìš”ê¸ˆì œ ë³€ê²½**: í˜„ì¬ ì‚¬ìš©ëŸ‰ì— ë§ëŠ” ìš”ê¸ˆì œë¡œ ë³€ê²½í•˜ì‹œë©´ ì ˆì•½ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "2. **ê°€ì¡± ê²°í•©**: ê°€ì¡±ê³¼ í•¨ê»˜ ê²°í•©í•˜ì‹œë©´ ì¶”ê°€ í• ì¸ì„ ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "3. **ë©¤ë²„ì‹­ í• ì¸**: KT ë©¤ë²„ì‹­ ë“±ê¸‰ì— ë”°ë¼ í• ì¸ í˜œíƒì´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê³ ê°ë‹˜ì˜ í˜„ì¬ ìš”ê¸ˆì œì™€ ì‚¬ìš© íŒ¨í„´ì„ í™•ì¸í•˜ì—¬ ìµœì ì˜ ë°©ì•ˆì„ ì°¾ì•„ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
    "ì¶”ê°€ë¡œ ê¶ê¸ˆí•˜ì‹  ì ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"ì¸í„°ë„·ì´ ì•ˆ ë¼ìš”\",\n",
    "        \"output\": \"\"\"ê³ ê°ë‹˜, ì¸í„°ë„· ì—°ê²° ë¬¸ì œë¡œ ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤.\n",
    "ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìˆœì„œëŒ€ë¡œ í™•ì¸í•´ ì£¼ì„¸ìš”:\n",
    "\n",
    "1. **ëª¨ë€/ê³µìœ ê¸° í™•ì¸**\n",
    "   - ì „ì›ì´ ì¼œì ¸ ìˆëŠ”ì§€ í™•ì¸\n",
    "   - ëª¨ë“  ì¼€ì´ë¸”ì´ ì œëŒ€ë¡œ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸\n",
    "\n",
    "2. **ì¬ì‹œì‘**\n",
    "   - ëª¨ë€ê³¼ ê³µìœ ê¸°ì˜ ì „ì›ì„ ëºë‹¤ê°€ 30ì´ˆ í›„ ë‹¤ì‹œ ì—°ê²°\n",
    "\n",
    "3. **ê¸°ê¸° ì„¤ì •**\n",
    "   - WiFiê°€ ì¼œì ¸ ìˆëŠ”ì§€ í™•ì¸\n",
    "   - ì˜¬ë°”ë¥¸ ë„¤íŠ¸ì›Œí¬ì— ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸\n",
    "\n",
    "ìœ„ ë°©ë²•ìœ¼ë¡œë„ í•´ê²°ë˜ì§€ ì•Šìœ¼ë©´ ê³ ê°ì„¼í„°(100ë²ˆ)ë¡œ ì—°ë½ ì£¼ì‹œë©´\n",
    "ì›ê²© ì ê²€ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Few-shot í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\")\n",
    "])\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "# ìµœì¢… í”„ë¡¬í”„íŠ¸\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ 10ë…„ ê²½ë ¥ì˜ ì¹œì ˆí•œ KT ê³ ê°ì„¼í„° ìƒë‹´ì›ì…ë‹ˆë‹¤.\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"\"\"ì°¸ê³  ìë£Œ:\n",
    "{context}\n",
    "\n",
    "ê³ ê° ì§ˆë¬¸: {question}\"\"\")\n",
    "])\n",
    "\n",
    "# Few-shot RAG ì²´ì¸\n",
    "few_shot_rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | final_prompt\n",
    "    | rag_model\n",
    ")\n",
    "few_shot_rag_chain"
   ],
   "id": "2e9ce4d4e9f12ef9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "few_shot_test_question = \"ë‚´ ì¸í„°ë„· ìš”ê¸ˆì´ ì™œ ì´ë ‡ê²Œ ë§ì´ ë‚˜ì™”ë‚˜ìš”?\"\n",
    "few_shot_response = few_shot_rag_chain.invoke(few_shot_test_question)\n",
    "\n",
    "few_shot_response.pretty_print()"
   ],
   "id": "883dfe51d6756fd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.2 ë©”ëª¨ë¦¬",
   "id": "bd84a19285652a77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ì£¼ì˜: í˜„ì¬ LangChain ì—ì„œ ì œê³µí•˜ëŠ” Conversation Memory ëŠ” ëª¨ë‘ Deprecated ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "# Conversation ë©”ëª¨ë¦¬ì˜ ê°œë…ì„ ì´í•´í•˜ê³  í™œìš©í•˜ëŠ” ê²ƒìœ¼ë¡œë§Œ í™œìš©í•˜ì‹œê³ , ì‹¤ì œ ì—…ë¬´ì—ëŠ” ì‚¬ìš©í•˜ì‹œë©´ ì•ˆë©ë‹ˆë‹¤.\n",
    "\n"
   ],
   "id": "c1332fa82a9038db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Chain ì „ëµ ë‹¤ë³€í™”",
   "id": "7cca3f343f77d1f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.1 ì§ˆë¬¸ ì˜ë„ ë¶„ì„ ì²´ì¸ ì¶”ê°€",
   "id": "782cf94667b31d39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ì˜ë„ ë¶„ì„ í”„ë¡¬í”„íŠ¸\n",
    "intent_analysis_sys_prompt = \"\"\"\n",
    "ë‹¹ì‹ ì€ KT ê³ ê°ì„¼í„°ì˜ ìƒë‹´ ì „ë¬¸ê°€ì´ë©´ì„œ ì˜ë„ ë¶„ì„ì— ê´€í•œ ìµœê³  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "ê³ ê°ì˜ ì§ˆë¬¸ì„ ê¹Šì´ ìˆê²Œ í•œêµ­ì–´ì˜ ë§¥ë½ì„ ì°¨ë¶„íˆ íŒŒì•…, ë¶„ì„í•˜ì—¬ ì •í™•í•œ ì˜ë„ë¥¼ íŒŒì•…í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "## ë¶„ì„ ê¸°ì¤€:\n",
    "1. ì£¼ìš” ì˜ë„: ê³ ê°ì´ ì›í•˜ëŠ” í•µì‹¬ ëª©ì \n",
    "2. ê¸´ê¸‰ë„: ë¬¸ì œì˜ ì‹œê¸‰ì„± (high/medium/low)\n",
    "3. ê°ì •: ê³ ê°ì˜ ê°ì • ìƒíƒœ (positive/neutral/negative)\n",
    "4. ìƒë‹´ì› í•„ìš”: ìë™ ì‘ë‹µìœ¼ë¡œ í•´ê²°ì´ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°\n",
    "\n",
    "\n",
    "## ì˜ë„ ì¹´í…Œê³ ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "{intent_categories}\n",
    "\n",
    "## Output Format:\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "intent_chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", intent_analysis_sys_prompt),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")"
   ],
   "id": "d3106e55d5afd521",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "class UserIntent(str, Enum):\n",
    "    \"\"\"ì‚¬ìš©ì ì˜ë„ ë¶„ë¥˜\"\"\"\n",
    "    INFO_INQUIRY = \"info_inquiry\"              # ì •ë³´ ë¬¸ì˜\n",
    "    SERVICE_APPLICATION = \"service_application\" # ì„œë¹„ìŠ¤ ì‹ ì²­\n",
    "    SERVICE_CHANGE = \"service_change\"          # ì„œë¹„ìŠ¤ ë³€ê²½\n",
    "    SERVICE_CANCELLATION = \"service_cancellation\" # ì„œë¹„ìŠ¤ í•´ì§€\n",
    "    BILLING_INQUIRY = \"billing_inquiry\"        # ìš”ê¸ˆ ë¬¸ì˜\n",
    "    TECHNICAL_SUPPORT = \"technical_support\"    # ê¸°ìˆ  ì§€ì›\n",
    "    COMPLAINT = \"complaint\"                    # ë¶ˆë§Œ ì‚¬í•­\n",
    "    GENERAL_INQUIRY = \"general_inquiry\"        # ì¼ë°˜ ë¬¸ì˜\n",
    "\n",
    "class IntentAnalysis(BaseModel):\n",
    "    \"\"\"ì˜ë„ ë¶„ì„ ê²°ê³¼\"\"\"\n",
    "    intent: UserIntent = Field(description=\"ì£¼ìš” ì˜ë„\")\n",
    "    sub_intent: str | None = Field(None, description=\"ì„¸ë¶€ ì˜ë„\")\n",
    "    confidence: float = Field(description=\"ì‹ ë¢°ë„ (0.0-1.0)\", ge=0.0, le=1.0)\n",
    "    keywords: list[str] = Field(description=\"í•µì‹¬ í‚¤ì›Œë“œ(5ê°œ ì´í•˜)\")\n",
    "    urgency: Literal[\"high\", \"medium\", \"low\"] = Field(description=\"ê¸´ê¸‰ë„\")\n",
    "    sentiment: Literal[\"positive\", \"neutral\", \"negative\"] = Field(description=\"ê°ì • ìƒíƒœ\")\n",
    "    requires_human: bool = Field(description=\"ìƒë‹´ì› ì—°ê²° í•„ìš” ì—¬ë¶€\")\n",
    "\n",
    "\n",
    "intent_parser = JsonOutputParser(pydantic_object=IntentAnalysis)"
   ],
   "id": "e9442cf88d12b52a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ì˜ë„ ë¶„ì„ ì²´ì¸\n",
    "intent_analysis_chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"format_instructions\": lambda x: intent_parser.get_format_instructions(),\n",
    "        \"intent_categories\": lambda x: \", \".join([i.value for i in UserIntent])\n",
    "    }\n",
    "    | intent_chat_prompt\n",
    "    | rag_model\n",
    "    | intent_parser\n",
    ")\n",
    "intent_analysis_chain"
   ],
   "id": "ed530a3cd8d39ad3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.2 ê°ì • ë¶„ì„ ì²´ì¸ ì¶”ê°€",
   "id": "48f98e41b0bd7e45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sentiment_analysis_sys_prompt = \"\"\"ë‹¹ì‹ ì€ ê³ ê°ì˜ ê°ì •ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"\"\"\n",
    "sentiment_analysis_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", sentiment_analysis_sys_prompt),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")"
   ],
   "id": "f44a8bb94c0ccdb1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.3 ì§ˆë¬¸ ì˜ë„ + ê°ì • ë¶„ì„ ë³‘ë ¬ ì²˜ë¦¬",
   "id": "eff4f2c3e4fbbf3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# TODO: ì‹¤ìŠµ!",
   "id": "728d60728807b60c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.4 ê° ì˜ë„ë³„ë¡œ ì „ë¬¸í™”ëœ ì²´ì¸ ë§Œë“¤ê¸°",
   "id": "1f6b7a7f373a0c86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ê° ì˜ë„ë³„ ì „ë¬¸ ì²´ì¸ (ì˜ˆì‹œ)\n",
    "\n",
    "billing_chain = ChatPromptTemplate.from_template(\n",
    "    \"ìš”ê¸ˆ ì „ë¬¸ ìƒë‹´ì›ì…ë‹ˆë‹¤. ìš”ê¸ˆ ê´€ë ¨ ë¬¸ì˜: {question}\"\n",
    ") | rag_model\n",
    "\n",
    "technical_chain = ChatPromptTemplate.from_template(\n",
    "    \"ê¸°ìˆ  ì§€ì›íŒ€ì…ë‹ˆë‹¤. ê¸°ìˆ ì  ë¬¸ì œ: {question}\\në‹¨ê³„ë³„ í•´ê²° ë°©ë²•ì„ ì•ˆë‚´í•˜ê² ìŠµë‹ˆë‹¤.\"\n",
    ") | rag_model\n",
    "\n",
    "service_chain = ChatPromptTemplate.from_template(\n",
    "    \"ì„œë¹„ìŠ¤ ê°€ì…/ë³€ê²½ ë‹´ë‹¹ì…ë‹ˆë‹¤. ë¬¸ì˜ ì‚¬í•­: {question}\"\n",
    ") | rag_model\n",
    "\n",
    "cancellation_chain = ChatPromptTemplate.from_template(\n",
    "    \"í•´ì§€ ë°©ì§€ íŒ€ì…ë‹ˆë‹¤. ê³ ê°ë‹˜ì˜ ë¶ˆí¸ì‚¬í•­: {question}\\ní˜œíƒì„ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\"\n",
    ") | rag_model\n",
    "\n",
    "general_chain = ChatPromptTemplate.from_template(\n",
    "    \"ì¼ë°˜ ìƒë‹´ì›ì…ë‹ˆë‹¤. ë¬¸ì˜ì‚¬í•­: {question}\"\n",
    ") | rag_model"
   ],
   "id": "c4cd2f7015aad54a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ì˜ë„ ê¸°ë°˜ ë¼ìš°íŒ… ì²´ì¸\n",
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "def classify_intent(question: str) -> str:\n",
    "    # TODO: ê³¼ì—° ì–´ë–»ê²Œ ë§Œë“¤ì–´ì•¼ ì˜ë„ë¥¼ í‚¤ì›Œë“œë¡œ ì¶”ì¶œí•  ìˆ˜ ìˆì„ê¹Œìš”?\n",
    "    return \"general\"\n",
    "\n",
    "intent_router = RunnableBranch(\n",
    "    (lambda x: classify_intent(x[\"question\"]) == \"billing\", billing_chain),\n",
    "    (lambda x: classify_intent(x[\"question\"]) == \"technical\", technical_chain),\n",
    "    (lambda x: classify_intent(x[\"question\"]) == \"service\", service_chain),\n",
    "    (lambda x: classify_intent(x[\"question\"]) == \"cancellation\", cancellation_chain),\n",
    "    general_chain  # ê¸°ë³¸ê°’\n",
    ")"
   ],
   "id": "a4f0e0625dc45ceb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 6.5 ê³ ê° ì •ë³´ ì¶”ê°€"
   ],
   "id": "3d8109efb7b09e92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CustomerContext(BaseModel):\n",
    "    \"\"\"ê³ ê° ì»¨í…ìŠ¤íŠ¸\"\"\"\n",
    "    customer_type: str = Field(description=\"ê³ ê° ìœ í˜•: VIP/ì¼ë°˜/ì‹ ê·œ\")\n",
    "    subscription_months: int = Field(description=\"ê°€ì… ê¸°ê°„(ì›”)\")\n",
    "    monthly_fee: int = Field(description=\"ì›” ìš”ê¸ˆ\")\n",
    "    has_issues: bool = Field(description=\"ìµœê·¼ ë¬¸ì œ ë°œìƒ ì—¬ë¶€\")"
   ],
   "id": "72c875f6a6d8a307",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_customer_aware_chain():\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "    \"\"\"ê³ ê° ì¸ì‹ ì²´ì¸ ìƒì„±\"\"\"\n",
    "\n",
    "    # VIP ì „ìš© ì²´ì¸\n",
    "    vip_chain = ChatPromptTemplate.from_template(\n",
    "        \"\"\"VIP ê³ ê°ë‹˜ê»˜ íŠ¹ë³„í•œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
    "        ê°€ì… ê¸°ê°„: {subscription_months}ê°œì›”\n",
    "        ì›” ìš”ê¸ˆ: {monthly_fee:,}ì›\n",
    "\n",
    "        ë¬¸ì˜ì‚¬í•­: {question}\n",
    "\n",
    "        VIP ì „ìš© í˜œíƒê³¼ í•¨ê»˜ ìµœìš°ì„ ìœ¼ë¡œ ì²˜ë¦¬í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\"\"\"\n",
    "    ) | rag_model | StrOutputParser()\n",
    "\n",
    "    # ì´íƒˆ ìœ„í—˜ ê³ ê° ì²´ì¸\n",
    "    churn_risk_chain = ChatPromptTemplate.from_template(\n",
    "        \"\"\"ì†Œì¤‘í•œ ê³ ê°ë‹˜, ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤.\n",
    "        ê³ ê°ë‹˜ê»˜ì„œ ê²ªìœ¼ì‹  ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  íŠ¹ë³„ í˜œíƒì„ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "        ë¬¸ì˜ì‚¬í•­: {question}\n",
    "\n",
    "        ê³ ê°ë‹˜ì„ ìœ„í•œ ë§ì¶¤ í˜œíƒì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤.\"\"\"\n",
    "    ) | rag_model | StrOutputParser()\n",
    "\n",
    "    # ì¼ë°˜ ê³ ê° ì²´ì¸\n",
    "    normal_chain = ChatPromptTemplate.from_template(\n",
    "        \"\"\"ì•ˆë…•í•˜ì„¸ìš”, KTì…ë‹ˆë‹¤.\n",
    "\n",
    "        ë¬¸ì˜ì‚¬í•­: {question}\n",
    "\n",
    "        ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\"\"\"\n",
    "    ) | rag_model | StrOutputParser()\n",
    "\n",
    "    # ì¡°ê±´ë¶€ ë¼ìš°íŒ…\n",
    "    return RunnableBranch(\n",
    "        # VIP ê³ ê°\n",
    "        (lambda x: x.get(\"customer_type\") == \"VIP\", vip_chain),\n",
    "        # ì´íƒˆ ìœ„í—˜ ê³ ê° (ì˜¤ë˜ëœ ê³ ê° + ìµœê·¼ ë¬¸ì œ)\n",
    "        (lambda x: x.get(\"subscription_months\", 0) > 24 and x.get(\"has_issues\", False), churn_risk_chain),\n",
    "        # ê¸°ë³¸\n",
    "        normal_chain\n",
    "    )\n",
    "\n",
    "# ê³ ê° ì¸ì‹ ì²´ì¸ ìƒì„±\n",
    "customer_aware_chain = create_customer_aware_chain()\n",
    "\n",
    "# ë‹¤ì–‘í•œ ê³ ê° ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸\n",
    "test_customers = [\n",
    "    {\n",
    "        \"customer_type\": \"VIP\",\n",
    "        \"subscription_months\": 60,\n",
    "        \"monthly_fee\": 150000,\n",
    "        \"has_issues\": False,\n",
    "        \"question\": \"í•´ì™¸ ë¡œë° ìš”ê¸ˆì´ ê¶ê¸ˆí•©ë‹ˆë‹¤\"\n",
    "    },\n",
    "    {\n",
    "        \"customer_type\": \"ì¼ë°˜\",\n",
    "        \"subscription_months\": 36,\n",
    "        \"monthly_fee\": 50000,\n",
    "        \"has_issues\": True,\n",
    "        \"question\": \"ì„œë¹„ìŠ¤ê°€ ë¶ˆë§Œì¡±ìŠ¤ëŸ¬ì›Œì„œ í•´ì§€ë¥¼ ê³ ë ¤ì¤‘ì…ë‹ˆë‹¤\"\n",
    "    },\n",
    "    {\n",
    "        \"customer_type\": \"ì‹ ê·œ\",\n",
    "        \"subscription_months\": 2,\n",
    "        \"monthly_fee\": 35000,\n",
    "        \"has_issues\": False,\n",
    "        \"question\": \"5G ìš”ê¸ˆì œë¡œ ë³€ê²½í•˜ê³  ì‹¶ì–´ìš”\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"ğŸ‘¥ ê³ ê°ë³„ ë§ì¶¤ ì‘ë‹µ:\\n\")\n",
    "for customer in test_customers:\n",
    "    print(f\"ê³ ê° ìœ í˜•: {customer['customer_type']} (ê°€ì… {customer['subscription_months']}ê°œì›”)\")\n",
    "    print(f\"Q: {customer['question']}\")\n",
    "    response = customer_aware_chain.invoke(customer)\n",
    "    print(f\"A: {response[:150]}...\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "\n",
    "\n",
    "# ì˜ë„ë³„ ì‘ë‹µ í…œí”Œë¦¿\n",
    "class IntentRouter:\n",
    "    \"\"\"ì˜ë„ë³„ ì‘ë‹µ ë¼ìš°í„°\"\"\"\n",
    "\n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "        self.templates = self._create_templates()\n",
    "\n",
    "    def _create_templates(self) -> Dict[UserIntent, ChatPromptTemplate]:\n",
    "        \"\"\"ì˜ë„ë³„ ì „ë¬¸ í…œí”Œë¦¿ ìƒì„±\"\"\"\n",
    "        return {\n",
    "            UserIntent.BILLING_INQUIRY: ChatPromptTemplate.from_template(\n",
    "                \"\"\"ìš”ê¸ˆ ì „ë¬¸ ìƒë‹´ì›ì…ë‹ˆë‹¤.\n",
    "                ì§ˆë¬¸: {question}\n",
    "                ë¶„ì„: {analysis}\n",
    "\n",
    "                ì •í™•í•œ ìš”ê¸ˆ ì •ë³´ì™€ ì ˆì•½ ë°©ë²•ì„ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\"\"\"\n",
    "            ),\n",
    "\n",
    "            UserIntent.TECHNICAL_SUPPORT: ChatPromptTemplate.from_template(\n",
    "                \"\"\"ê¸°ìˆ  ì§€ì›íŒ€ì…ë‹ˆë‹¤.\n",
    "                ì§ˆë¬¸: {question}\n",
    "                ê¸´ê¸‰ë„: {urgency}\n",
    "\n",
    "                ë‹¨ê³„ë³„ í•´ê²° ë°©ë²•ì„ ì•ˆë‚´í•˜ê² ìŠµë‹ˆë‹¤.\"\"\"\n",
    "            ),\n",
    "\n",
    "            UserIntent.COMPLAINT: ChatPromptTemplate.from_template(\n",
    "                \"\"\"ê³ ê°ë‹˜ì˜ ë¶ˆí¸ì„ í•´ê²°í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "                ì§ˆë¬¸: {question}\n",
    "                ê°ì •: {sentiment}\n",
    "\n",
    "                ì§„ì‹¬ìœ¼ë¡œ ì‚¬ê³¼ë“œë¦¬ë©° ì¦‰ì‹œ ê°œì„ í•˜ê² ìŠµë‹ˆë‹¤.\"\"\"\n",
    "            ),\n",
    "\n",
    "            UserIntent.SERVICE_CHANGE: ChatPromptTemplate.from_template(\n",
    "                \"\"\"ì„œë¹„ìŠ¤ ë³€ê²½ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
    "                ì§ˆë¬¸: {question}\n",
    "\n",
    "                ìµœì ì˜ ì„œë¹„ìŠ¤ë¡œ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\"\"\"\n",
    "            )\n",
    "        }\n",
    "\n",
    "    def route_and_respond(self, question: str, analysis: IntentAnalysis) -> str:\n",
    "        \"\"\"ì˜ë„ì— ë”°ë¼ ì ì ˆí•œ ì‘ë‹µ ìƒì„±\"\"\"\n",
    "        # ê¸°ë³¸ í…œí”Œë¦¿\n",
    "        default_template = ChatPromptTemplate.from_template(\n",
    "            \"KTì…ë‹ˆë‹¤. {question}ì— ëŒ€í•´ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\"\n",
    "        )\n",
    "\n",
    "        # ì˜ë„ë³„ í…œí”Œë¦¿ ì„ íƒ\n",
    "        template = self.templates.get(analysis.intent, default_template)\n",
    "\n",
    "        # ì²´ì¸ ì‹¤í–‰\n",
    "        chain = template | self.llm\n",
    "\n",
    "        response = chain.invoke({\n",
    "            \"question\": question,\n",
    "            \"analysis\": analysis.model_dump_json(),\n",
    "            \"urgency\": analysis.urgency,\n",
    "            \"sentiment\": analysis.sentiment\n",
    "        })\n",
    "\n",
    "        return response.content"
   ],
   "id": "83879d79e5c9961",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ì •ë¦¬",
   "id": "e48183303e88f198"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1) ì…ë ¥ì— ëŒ€í•´ ì „ì²˜ë¦¬ ë° ë¶„ì„\n",
    "2) ë³‘ë ¬ ë¶„ì„ ë° ë°ì´í„° ì²˜ë¦¬\n",
    "3) Routing ê²°ì •\n",
    "4) ìµœì¢… RAG Chain í™•ì •\n",
    "\n",
    "### ë¬¸ì œì \n",
    "ìˆœì°¨ì ì¸ ì§„í–‰(ë‹¨ë°©í–¥), 1ê°œë¼ë„ ì‹¤íŒ¨í•˜ë©´ ë˜ëŒì•„ì˜¬ ìˆ˜ ì—†ìŒ(ì „ì²´ ì‹¤íŒ¨)"
   ],
   "id": "6ae5a4ac29ced3f3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
